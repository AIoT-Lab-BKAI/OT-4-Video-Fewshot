{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:25:50.993354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "import ot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scheduler(timesteps, start=0.0001, end=0.02):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns linear schedule for beta\n",
    "    \"\"\"\n",
    "    return torch.linspace(start, end, timesteps)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \n",
    "    \"\"\" \n",
    "    Returns values from vals for corresponding timesteps\n",
    "    while considering the batch dimension.\n",
    "    \n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    output = vals.gather(-1, t.cpu())\n",
    "    return output.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
    "    \"\"\" \n",
    "    Takes an image and a timestep as input and \n",
    "    returns the noisy version of it after adding noise t times.\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x_0.shape)\n",
    "    \n",
    "    # mean + variance\n",
    "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "\n",
    "# Define beta schedule\n",
    "T = 300\n",
    "betas = linear_scheduler(timesteps=T)\n",
    "\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 112\n",
    "forward_transform = [\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # Scales data into [0,1] \n",
    "    transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "]\n",
    "forward_transform = transforms.Compose(forward_transform)\n",
    "backward_transform = [\n",
    "    transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "    transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "    transforms.Lambda(lambda t: t * 255.),\n",
    "    transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "    transforms.ToPILImage()\n",
    "]\n",
    "backward_transform = transforms.Compose(backward_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01/00000.jpg')\n",
    "img = forward_transform(img)\n",
    "t = torch.Tensor([1]).type(torch.int64)\n",
    "img, noise = forward_diffusion_sample(img, t)\n",
    "img = backward_transform(img)\n",
    "img.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_video(frames):\n",
    "    # return randomly 4 segments of 16 frames each\n",
    "    # each segment is a tensor of shape (16, 112, 112, 3)\n",
    "    while len(frames) < 16:\n",
    "        frames += frames\n",
    "    start_idx = np.random.randint(len(frames) - 16 + 1, size=4)\n",
    "    segments = []\n",
    "    for i in range(4):\n",
    "        x = np.stack([frames[j] for j in range(start_idx[i], start_idx[i]+16)])\n",
    "        segments.append(x)\n",
    "    return segments\n",
    "\n",
    "def prep_video():\n",
    "    video_path = 'data/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01'\n",
    "    frames_path = glob.glob(os.path.join(video_path, '*.jpg'))\n",
    "    frames_path.sort()\n",
    "    frames = [Image.open(path) for path in frames_path]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((4)) / 4\n",
    "y = torch.ones((4)) / 4\n",
    "z = torch.rand(4, 4)\n",
    "z1 = ot.sinkhorn(x, y, z, 0.01, numItermax=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.2536e-43, 2.5000e-01, 9.4096e-10, 2.8499e-13],\n",
      "        [5.7574e-02, 2.3579e-05, 1.9240e-01, 5.3894e-31],\n",
      "        [1.9246e-01, 4.0652e-20, 5.7543e-02, 2.5366e-15],\n",
      "        [1.2835e-10, 4.6883e-06, 8.4780e-05, 2.4991e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
